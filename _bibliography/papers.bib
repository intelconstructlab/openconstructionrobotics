---
---

@string{aps = {American Physical Society,}}

@InProceedings{Duan2025,
  author    = {Duan, Kangkang and Zhu, Zehao and Zou, Zhengbo},
  booktitle = {2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Indoor FireRescue Radar: 4D Indoor Millimeter Wave Dataset and Analysis for Hazardous Environment Perception},
  year      = {2025},
  pages     = {18620-18627},
  doi       = {10.1109/IROS60139.2025.11246924},
  keywords  = {Point cloud compression;Laser radar;Three-dimensional displays;Buildings;Object detection;Millimeter wave radar;Radar imaging;Cameras;Robot sensing systems;Indoor environment},
  publisher = {ICRA},
  bibtex_show={true},
  html={https://huggingface.co/datasets/yysd123/indoor_mmwave},
  video = {https://youtu.be/_ZRaFP9D4Qk?si=XlF-z7xamxjO3DMT},
  preview={firedataset.png},
}

@Article{Cai2025a,
  author   = {Weijia Cai and Lei Huang and Zhengbo Zou },
  journal  = {ASCE OPEN: Multidisciplinary Journal of Civil Engineering},
  title    = {RoboAuditor-LLM: A Robotic System for Energy Auditing via a Large Language Model and an Actionable Semantic Feature Map},
  year     = {2025},
  number   = {1},
  pages    = {04025013},
  volume   = {3},
  abstract = { Buildings significantly contribute to electricity consumption, increasing the risk of costly blackouts and safety issues due to growing demand. However, plug loads remain underexplored in energy audits due to their complexity and variability, highlighting a critical gap in energy management practices. We propose RoboAuditor-LLM, a robotic system for automating initial steps of energy audits in indoor environments, by translating human inspectors’ instruction into executable robot actions. RoboAuditor-LLM consists of three modules: a large language model (LLM) planner for parsing human instructions and generating executable actions for robots, an Actionable Semantic Feature Map for providing spatial information of static objects and corresponding goal poses, and a Robot Toolbox for providing diverse downstream skills, including navigation, device counting, and device status verification. RoboAuditor-LLM utilizes open-source foundation models’ reasoning capacity for understanding complex human instructions, and coding ability for translating natural language into executable code for robots. We evaluate RoboAuditor-LLM in real-world institutional offices using a quadruped robot. We achieve a 76.91\% average success rate for device localization and LLM-matched score of 4.01 (out of 5.00) for device status recognition. },
  doi      = {10.1061/AOMJAH.AOENG-0087},
  eprint   = {https://ascelibrary.org/doi/pdf/10.1061/AOMJAH.AOENG-0087},
  url      = {https://ascelibrary.org/doi/abs/10.1061/AOMJAH.AOENG-0087},
  bibtex_show={true},
  publisher = {ASCE}, 
  preview={rba-llm-preview.png},
}


@Article{Cai2025,
  author   = {Weijia Cai and Lei Huang and Zhengbo Zou },
  journal  = {Journal of Computing in Civil Engineering},
  title    = {Leveraging Open-Vocabulary Object Detection in Goal-Oriented Navigation for Assessing Indoor Energy–Intensive Devices},
  year     = {2025},
  number   = {5},
  pages    = {04025060},
  volume   = {39},
  abstract = { Energy auditing is crucial to improve energy efficiency in buildings. This paper focuses on the initial stage of energy auditing: collecting data on energy-intensive devices, which account for 20\% of major building energy consumption. Manual data collection for these devices significantly increases the workload and duration of energy audits because it involves identifying and localizing various device types in unknown environments. Existing robotic approaches to automate this process are either not scalable to unseen objects or lack effective exploration strategies for object localization. We present a robotic system for automating the initial step of energy audits in indoor environments, aimed at efficient navigation and precise localization of energy-intensive devices. This system integrates an RGB-D SLAM (simultaneous localization and mapping) module for mapping, a Relevance Mapper for goal-oriented exploration, and a Navigator for path planning. The system uses a pretrained open-vocabulary semantic segmentation model to identify human-queried, energy-intensive devices without additional training and to optimize exploration. Tested on 12 buildings from the HM3D data set in simulation, our approach demonstrates an improved success rate in detecting targeted energy-intensive objects, achieving a 73.38\% success rate, compared to a control group without Relevance Mapper, which only reached 67.38\%. Notably, our approach shows an evident improvement in large-scale buildings by 12\%. Furthermore, we conducted real-world tests with a quadruped robot equipped with an RGB-D camera to validate our system’s effectiveness in complex real-world environments, resulting in an 86.67\% success rate. Our method offers a scalable, cost-effective solution for initial steps of energy auditing to facilitate informed decisions on building system retrofitting. },
  doi      = {10.1061/JCCEE5.CPENG-6376},
  eprint   = {https://ascelibrary.org/doi/pdf/10.1061/JCCEE5.CPENG-6376},
  url      = {https://ascelibrary.org/doi/abs/10.1061/JCCEE5.CPENG-6376},
  bibtex_show={true},
  publisher = {ASCE},
  preview={blipmap2023-demo.png},
}

@inproceedings{Zhang2024,
  author = {Zhang, Hao Xuan and Yang, Yilin and Zou, Zhengbo},
  title = {ICON drone: Autonomous indoor exploration using Unmanned Aerial Vehicle for semantic 3D reconstruction},
  year = {2024},
  isbn = {9798400707063},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3671127.3698172},
  doi = {10.1145/3671127.3698172},
  abstract = {Keeping an up-to-date 3D representation of buildings is a crucial yet time-consuming step for Building Information Modeling (BIM) and digital twins. To address this issue, we propose ICON drone, an unmanned aerial vehicle (UAV) designed to navigate indoor environments autonomously and generate point clouds. ICON drone is constructed using a 250mm quadcopter frame, a Pixhawk flight controller, an onboard computer, an RGB-D camera and an IMU sensor. The UAV navigates autonomously using a visual-inertial odometer (VIO) and frontier-based exploration. The collected RGB images during the flight are used for 3D reconstruction and semantic segmentation. The final outputs are point clouds with building components and material labelling for BIM generation. We tested the UAV in three scenes in an educational building: classroom, lobby, and lounge. Results show that the ICON drone could: 1) explore all three scenes autonomously, 2) generate absolute scale point clouds with mean point-to-point distances of 0.0644, 0.0518, 0.0727m compared to point clouds collected using a high-fidelity terrestrial LiDAR scanner, 3) label the point cloud with corresponding building components and material with mIoU of 0.588 and 0.629.},
  booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
  pages = {66–76},
  numpages = {11},
  keywords = {Deep learning, Photogrammetry, Robotics, Scan-to-BIM, Simultaneous localization and mapping},
  location = {Hangzhou, China},
  series = {BuildSys '24}
  bibtex_show={true},
  publisher = {ACM},
  preview={icondrone.png},
}

@InBook{Suen2024,
  author    = {Christine Wun Ki Suen and Ziming Liu and Yangming Shi and Zhengbo Zou },
  pages     = {682-689},
  title     = {ICON-Pose: Toward Egocentric Action Recognition for Intelligent Construction},
  abstract  = { The working environment of construction workers is often hazardous and dynamic, leading not only to decline in worker productivity but also fatal accidents. Monitoring of workers’ behavior has thus gained increasing attention in the construction community for hazard monitoring, ergonomic analysis, and productivity estimation. Egocentric action recognition is robust and promising in identifying, localizing, and tracking workers’ actions. However, the insufficiency of publicly available datasets designated for egocentric construction workers’ action recognition hampers the training and evaluation of existing and newly developed deep-learning models. In this regard, this paper introduces ICON-Pose, the first open dataset built specifically for estimating construction workers’ poses via egocentric view. ICON-Pose offers hundreds of egocentric images and corresponding 2D workers’ body joints in 38 actions, categorized in 10 basic construction tasks, including “connect,” “cover,” “cut,” “dig,” “finish,” “place,” “position,” “spray,” “spread,” and “others.” ICON-Pose with the proposed pose estimation model demonstrates the ability in accurately depicting diverse construction workers’ poses as well as the robustness in describing unique construction poses. The proposed dataset is expected to invigorate and support artificial intelligence research in construction workers’ behavior tracking and has the potential of serving as a benchmark dataset for subsequent analysis. },
  booktitle = {Computing in Civil Engineering 2023},
  doi       = {10.1061/9780784485224.082},
  eprint    = {https://ascelibrary.org/doi/pdf/10.1061/9780784485224.082},
  url       = {https://ascelibrary.org/doi/abs/10.1061/9780784485224.082},
  year      = {2024},
  bibtex_show={true},
  publisher = {ASCE},
  html={https://github.com/christine715/ICON-Pose},
  preview={iconpose.png},
}

@Article{Cai2023,
  author   = {Weijia Cai and Lei Huang and Zhengbo Zou},
  journal  = {Automation in Construction},
  title    = {Actively-exploring thermography-enabled autonomous robotic system for detecting and registering HVAC thermal leaks},
  year     = {2023},
  issn     = {0926-5805},
  pages    = {104901},
  volume   = {152},
  abstract = {The inefficiency, labor-intensity, and possibility of automation of the current practice of HVAC system inspections, which heavily relies on human inspectors, are being questioned. This paper describes a lightweight and reproducible robotic system dubbed AcTEA-bot, that automatically detects and locates thermal leaks in ceiling environments while self-navigating. AcTEA-bot is designed and built upon three modules, including an active visual SLAM module, a thermal leak detection module, and a thermal leak registration module. To evaluate the effectiveness of AcTEA-bot, a true-to-scale ceiling environment containing five thermal leaks is built, and 30 experiments are conducted where AcTEA-bot starts with different poses and conducts the inspection task. Results demonstrate that thermal leaks of multiple types in ceiling environments can be accurately detected and located.},
  doi      = {https://doi.org/10.1016/j.autcon.2023.104901},
  keywords = {Robotics, HVAC inspection, Leakage detection, Thermography, SLAM, Deep learning, Computer vision},
  url      = {https://www.sciencedirect.com/science/article/pii/S0926580523001619},
  bibtex_show={true},
  publisher = {AutoCon},
  html={https://www.sciencedirect.com/science/article/pii/S0926580523001619},
  preview={acteabot_demo.gif},
}

@inproceedings{Cai2022,
  author = {Cai, Weijia and Zhang, Le and Huang, Lei and Yu, Xinran and Zou, Zhengbo},
  title = {TEA-bot: a thermography enabled autonomous robot for detecting thermal leaks of HVAC systems in ceilings},
  year = {2022},
  isbn = {9781450398909},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3563357.3564054},
  doi = {10.1145/3563357.3564054},
  abstract = {We propose TEA-bot (Thermography Enabled Autonomous Robot) to address the problem of labor-intensive manual inspections of thermal leaks in Heating Ventilation and Air Conditioning (HVAC) systems while avoiding installation of sensor networks, which can be challenging and expensive for existing buildings. TEA-bot is an Unmanned Ground Vehicle (UGV) designed to navigate in ceilings using visual-based Simultaneously Localization And Mapping (SLAM) while detecting thermal leaks from HVAC systems using Convolutional Neural Networks (CNN). TEA-bot uses inexpensive 3D printed parts as the bones, a single-board computer (SBC) as the brain, an RGB-D camera as the eyes, and a thermal camera as the leak detector. We build an in-lab ceiling environment as a true-to-size testing site with five types of common leaks in HVAC systems (e.g., improper connection) to test the feasibility and effectiveness of TEA-bot. Results show that TEA-bot can 1) generate high-resolution ceiling maps in the format of point clouds for existing buildings without Building Information Models (BIMs), with an average error of 1.56 inches in duct length measurements; 2) identify leak types with a precision of 86.60\% using the thermal camera images; and 3) register leaks onto the point cloud maps, providing a holistic and intuitive view of leak locations in an unknown ceiling environment.},
  booktitle = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
  pages = {30–39},
  numpages = {10},
  keywords = {HVAC leak detection, deep learning, robotics, simultaneous localization and mapping, thermography},
  location = {Boston, Massachusetts},
  series = {BuildSys '22},
  bibtex_show={true},
  publisher = {ACM},
  html={https://dl.acm.org/doi/abs/10.1145/3563357.3564054},
  preview={TEA-bot3D.png},
}

@Article{Huang2023,
  author   = {Lei Huang and Weijia Cai and Zihan Zhu and Zhengbo Zou},
  journal  = {Automation in Construction},
  title    = {Dexterous manipulation of construction tools using anthropomorphic robotic hand},
  year     = {2023},
  issn     = {0926-5805},
  pages    = {105133},
  volume   = {156},
  abstract = {Emerging studies are utilizing reinforcement learning (RL) and imitation learning (IL) to control large-scale robots in heavy construction tasks. There is limited attention given to the automation of delicate tasks typically performed manually. This paper proposes the control of an anthropomorphic robotic hand with a high degree of freedom for the manipulation of construction tools in a learning-based approach. For controlling the robotic hand, a simulation-based policy learning framework based on pretraining policies through IL is presented, subsequently fine-tuning them for construction tool manipulation using RL. In experimental trials, six policies are trained for the robotic hand to grasp six different construction tools. The results indicate that each of the learned policies enables the robotic hand to manipulate the corresponding tool with an almost 100% success rate, demonstrating resilience when confronted with tools of different scales. Additionally, the paper showcases the potential for scaling up the fundamental policy for downstream applications.},
  doi      = {https://doi.org/10.1016/j.autcon.2023.105133},
  keywords = {Construction robot, Reinforcement learning, Imitation learning, Dexterous manipulation, Robotic hand, Anthropomorphic},
  url      = {https://www.sciencedirect.com/science/article/pii/S092658052300393X},
  bibtex_show={true},
  publisher = {AutoCon},
  html={https://www.sciencedirect.com/science/article/pii/S092658052300393X?via%3Dihub},
  preview={dexcon_demo.gif},
  video = {https://youtu.be/cOGNhlwFt4w}
}

